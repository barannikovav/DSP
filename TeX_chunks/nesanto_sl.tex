

	\section{Переходная вероятность, переходная плотность, переходные вероятности состояний}
	
	\textbf{Автор:} Нестеров Антон Сергеевич, Б-01-007
	
	\subsection{Понятие случайного процесса}
	Функцию $X(t)$ называют \textbf{случайной}, если ее значения при любом аргументе $t$ являются случайной величиной.
	
	\textbf{Случайным процессом} называется случайная функция $X(t)$, аргумент которой будем называть временем. 
	
	Рассмотрим некоторую систему, в которой протекает изучаемый случайный процесс. Назовем \textbf{состоянием} системы (состоянием случайного процесса) возможные значения случайных величин, образующих этот случайный процесс. Под испытаниями системы будем понимать изменения ее состояний. Процесс перехода системы из одного состояния в другое, про-текающий случайным образом, является случайным процессом. Т.о., случайный процесс есть семейство случайных величин, заданных на одном и том же пространстве элементарных событий $\Omega$, зависящих от параметра $t\in T$.
	
	Частным видом случайных процессов являются марковские процессы, позволяющие описывать поведение разнообразных систем. 
	
	Случайный процесс, протекающий в некоторой системе, называют марковским процессом, если он обладает характерным свойством: для каждого фиксированного момента времени $t_0$ вероятность любого состояния системы в будущем (при $t\textgreater t_0$) зависит только от ее состояния в настоящем (при $t = t_0$) и не зависит от того, как развивался этот процесс в прошлом. Т.о., в марковских процессах не имеет значение «предыстория» модели, а существенно лишь ее нынешнее состояние.
	
	В зависимости от характера множества значений функции $X(t)$ и переменной $t$, различают отдельные виды случайных процессов:
	\begin{itemize}
		\item с дискретным состоянием и дискретным временем (цепь Маркова);
		\item с дискретным состоянием и непрерывным временем (непрерывная цепь Маркова);
		\item с непрерывным состоянием и дискретным временем (марковские после-довательности);
		\item с непрерывным состоянием и непрерывным временем.
	\end{itemize}
	
	\subsection{Марковские цепи}
	Рассмотрим марковский процесс с дискретными состояниями $S_1,\dots,~S_k$. Тогда условная вероятность $p_{ij}(n)$ того, что в отдельном $n$-м испытании наступит событие $X_n = S_i$ (где $i = 1,~2,\dots,~k$), при условии, что в ($n-1$)-м испытании наступило событие $X_{n-1} = S_j$ ($i,~j = 1,~2,\dots,~k$), явно не зависит от результата предшествующих испытаний.
	
	Любой марковский процесс можно описать с помощью вероятностей состояний (некоторых событий) и переходных вероятностей.
	
	\textbf{Вероятностями состояний $p_n(t)$ марковского случайного процесса} называют вероятности того, что случайный процесс (система) в момент времени $t$ находится в состоянии $S_n$:
	
	$$
	p_n(t) = P\{X(t)= S_n\}.
	$$
	
	\textbf{Переходными вероятностями марковского процесса} называются условные вероятности перехода процесса (системы) из одного состояния ($i$) в некоторое другое ($j$) за время $\Delta t$, если известно, что в момент $t$ система находилась в $i$-ом состоянии:
	
	$$
	P_{ij}(\Delta t)=P\{X(t+\Delta t)=S_j\bigg|X(t)=S_i\}.
	$$
	
	Цепь Маркова с дискретным временем -- это цепь, изменение состояний которой происходит в определенные фиксированные моменты времени. В этом случае моменты времени $t_1,~t_2,\dots,~t_m,\dots$, в которые система меняет свое состояние, рассматриваются как последовательные шаги марковского процесса, где независимым аргументом можно считать не время $t$, а порядковый номер шага $m$. Тогда случайный процесс может быть представлен как последовательность состояний $S(0),~S(1),\dots,~S(m)$, которые рассматривают как последовательность случайных событий. В этих обозначениях $S(0)$ -- начальное состояние системы, $S(1)$ -- ее состояние после первого шага,$\dots$, $S(m)$ -- ее состояние после $m$-го шага.
	
	Переходные состояния в цепи Маркова за один шаг $p_{ij}$ можно записать в виде матрицы переходных вероятностей, которую принято называть переходной матрицей:
	
	$$
	\pi_1(n) = P(n) = ||p_{ij}(n)|| = \begin{pmatrix}
		p_{11}(n) & p_{12}(n) & \dots & p_{1j}(n) & \dots & p_{1k}(n) \\
		p_{21}(n) & p_{22}(n) & \dots & p_{2j}(n) & \dots & p_{2k}(n) \\
		\dots & \dots & \dots & \dots & \dots & \dots \\
		p_{i1}(n) & p_{i2}(n) & \dots & p_{ij}(n) & \dots & p_{ik}(n) \\
		\dots & \dots & \dots & \dots & \dots & \dots \\
		p_{k1}(n) & p_{k2}(n) & \dots & p_{kj}(n) & \dots & p_{kk}(n) \\
	\end{pmatrix}
	$$ 
	
	где $p_{ij}(n)$ -- вероятность перехода за один шаг из состояния $S_i$ в состояние $S_j$ ($i\neq j$), а $p_{ii}(n)$ -- вероятность задержки системы в состоянии $S_i$ на $n$-ом шаге.
	
	Каждая строка такой квадратной матрицы размера $k\times k$ отражает вероятности перехода из одного состояния в другое, которые образуют полную группу событий. Поэтому сумма переходных вероятностей каждой строки этой матрицы равна единице:
	
	$$
	\sum_{j = 1}^{k}p_{ij} = 1,~i=1,~2,\dots,~k.
	$$
	
	Элементы столбцов матрицы показывают вероятности всех возможных переходов системы за один шаг в заданное $j$-е состояние. Если заданы безусловные вероятности состояний в момент времени $m$, то вероятности состояний в момент времени $m+1$ равны
	
	\begin{equation}\label{eq1}
		p_j(m+1) = \sum_{j = 1}^{k}p_{i}(m)p_{ij}(m)
	\end{equation}
	
	или в матричном виде
	
	$$
	p(m+1)= p(m)P(m),~\text{или}~p^T(m+1)= P^T(m) p^T(m),
	$$
	
	где $p(m)$ -- строка, а $p^T(m)$ -- столбец безусловных вероятностей. Заметим, что для транспонированной матрицы $P^T$ сумма элементов каждого столбца равна $1$.
	
	Марковский процесс называется однородным, если вероятности перехода за единицу времени не зависят от того, в какой момент времени происходит этот переход. Марковский случайный процесс с дискретным временем и дискретным конечным множеством состояний -- цепь Маркова -- является примером наиболее простого однородного марковского процесса. Цепь Маркова называется однородной, если условная вероятность $p_{ij}$ перехода из состояния $i$ в состоянии $j$ не зависит от номера испытания (т.е. от времени), тогда
	
	$$
	P(1)=P(2)=\dots=P(k)= P.
	$$
	
	Определим для однородной марковской цепи матрицу перехода $\pi_n$ за $n$ шагов, т.е. вероятность того, что, находясь в состоянии $S_i$, через $n$ шагов система окажется в состоянии $S_j$. Согласно формуле полной вероятности нужно учитывать все промежуточные состояния:
	
	\begin{equation}\label{eq2}
		\pi_n = \bigg|\bigg|P_{ij}(n)\bigg|\bigg|,~\text{где}~P_{ij}(n) = \sum_{s=1}^{k}P_{is}(m)P_{sj}(n - m),
	\end{equation}
	
	т.е. для любого $m\leq n$ верно матричное уравнение $\pi_n =\pi_n\pi_{n - m}$. Очевидно, независимость от $m$ приводит к тривиальному решению
	
	$$
	\pi_n = \pi_1^n,
	$$
	
	которое и выражает однородность процесса.
	
	При $m=1$ $P_{ij}(1)= p_{ij}$, и формула (\ref{eq2}) имеет более простой вид
	
	\begin{equation}\label{eq3}
		P_{ij}(n) = \sum_{s = 1}^{k}p_{is}P_{sj}(n-1)
	\end{equation}
	
	т.е. задается рекуррентной формулой.
	
	В марковской цепи при $n\to\infty$ в системе устанавливается так называемый предельный стационарный режим, заключающийся в том, что система случайным образом меняет свои состояния, причем вероятность каждого из них не зависит от времени: каждое из состояний осуществляется с постоянной вероятностью (предельные вероятности состояний цепи Маркова).

	
	\begin{theorem}[о предельных вероятностях] Если существует номер $f$ такой, что все элементы матрицы перехода $\pi_f$ положительны, то существуют постоянные числа $р_j (j=1\dots k)$, такие, что независимо от $i$ существуют пределы
	
	\begin{equation}\label{eq4}
		\lim\limits_{n\to\infty}P_{ij}(n) = p_j.
	\end{equation}
	\end{theorem}
	
	Таким образом, при больших значениях $n$ величины $р_j$ можно считать вероятностями нахождения системы в состоянии $S_j$ на $n$-ом шаге. Среднее время пребывания этой системы в состоянии $S_i$ за время $T$ равно $p_iT$, а среднее время возвращения в состояние $S_i$ равно $1/p_i$, т.е., если отсчитывать время от последнего события $X(0)=S_i$, то время возвращения $m$ -- первое наступление этого же события $X(m)=S_i$ (первое наступление события распределено геометрически).
	
	Назовем \textbf{потоком событий} последовательность однородных событий, следующих одно за другим через некоторые случайные интервалы времени. Под действием таких потоков понимают «мгновенные» переходы системы из одного состояния в другое.
	
	Цепь Маркова с непрерывным временем -- это цепь, изменение состояний которой происходит в любые случайные моменты времени. В такой системе вероятность перехода системы из одного состояния в другое в заданный момент времени $t_0$ бесконечно мала (как вероятность конкретного значения НСВ). Поэтому от переходных вероятностей $p_{ij}$ нужно перейти к плотности вероятности перехода в момент времени $t_0$, которая называется интенсивностью потока событий.
	
	\textbf{Плотность вероятности перехода} $\lambda_{ij}$ в момент времени $t_0$ есть вероятность $p_{ij}(dt)$ перехода системы состояния $S_i$ в состояние $S_j$ за время от $t_0$ до $t_0+dt$:
	
	\begin{equation}\label{eq5}
		\lambda_{ij}(t_0) = \lim\limits_{dt\to 0}\left.\frac{p_{ij}(dt)}{dt}\right|_{t = t_0}
	\end{equation}
	
	т.е. среднее число событий в единицу времени. Поскольку при любом времени $t_0$ сумма $p_{ij}(dt)=1$, то сумма всех $\lambda_{1j}(t_0)$ обращается в бесконечность (расходится) при взятии предела. Очевидно, этой бесконечности соответствует $\lambda_{ij}(t_0)$, т.е. плотность задержки, поскольку $p_{ij}(t_0+dt)\to p_{ij}(t_0)$ и конечна при $dt\to 0$. Очевидно, для однородной марковской цепи плотность вероятности перехода $\lambda_{ij}=const$, т.е. не зависит от времени $t$.
	
	Марковский случайный процесс с непрерывным временем и дискретным конечным множеством состояний служит теоретической основой для исследования реальных систем массового обслуживания.
	
	Для анализа цепи Маркова составляют граф состояний, где вершины -- все возможные состояния цепи (системы), а дуги -- ненулевые вероятности всех возможных переходов за один шаг из одного состояния в другое. При построении графа состояний марковского процесса обычно над стрелками между состояниями указывают плотности вероятностей перехода. Такой ориентированный граф состояний называют размеченным. Размеченный граф позволяет легко составить уравнения, которые описывают безусловные вероятности состояний $p_1(t),~p_2(t),\dots,~p_k(t)$ как функции времени: изменение (производная) вероятности каждого состояния происходит за счет всех потоков вероятности, направленных из других состояний в данное, и всех потоков вероятности, направленных из данного состояния в другие с учетом знаков алгебраической суммы.
	
	Эти уравнения называются уравнениями Колмогорова:
	
	\begin{equation}\label{eq6}
		\frac{dp_i(t)}{dt} = p_i'(t) = \sum_{i\neq j\neq 1}^{k}\lambda_{ij}p_j(t) - p_i(t)\sum_{i\neq j\neq 1}^{k}\lambda_{ij}
	\end{equation}
	
	где величина $\lambda_{ij}p_i(t)$ есть поток вероятности перехода из состояния $S_i$ в $S_j$.
