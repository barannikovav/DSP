
\section{Гаусовские случайные процессы}

 \textbf{Автор:} Курицына Кристина Александровна, Б-01-009

\begin{definition} Случайный процесс $\{\xi(t), t \in T \}$
называется \textbf{гауссовским (нормальным)}, если все его конечномерные распределения являются нормальными, то есть для любых $k\geq 1$ и любых $t_1, \dots , t_k \in  T$ случайный вектор $(\xi(t_1 ), \dots , \xi(t_n))$ имеет нормальное распределение. \cite{NatanTeorVero2007}
\end{definition}

Напомним, что по определению вектор $\xi = (\xi_1, \dots , \xi_n)$ имеет нормальное распределение, если его характеристическая функция имеет вид:
\[\varphi_\xi (s) = exp(i\mu^T s - \frac{1}{2}s^T Rs)\]
для любого $ s \in \mathbb{R} ^{n} $. Здесь вектор $\mu = \mathbb{E} \xi \in \mathbb{R}^{n\times n}$ -  математическое ожидание вектора $ \xi$, а матрица
\[R = \mathbb{E} \xi \xi^T = \mathbb{E} (\xi - \mathbb{E} \xi)(\xi-\mathbb{E} \xi)^T \in \mathbb{R}^{n\times n}\]
- это корреляционная матрица вектора $\xi$. Если нормальный вектор имеет математическое ожидание $\mu$ и корреляционную матрицу $R$, то пишут, что $\xi \in N(\mu , R)$. \cite{NatanTeorVero2007}

То есть действительный случайный процесс $\xi (t)$, $t \in T$ называется гауссовским, если его характеристическая функция имеет следующий вид:
\[\Psi _\xi (z_1, \dots, z_k ; t_1, \dots, t_k ) = M\left\{exp\left(i\sum_{j = 1}^{k} z_j \xi(t_j) \right)\right\} = \]
\[= exp\left(i\sum_{j=1}^{k} z_j m_\xi (t_j) - \frac{1}{2} \sum_{l=1}^{k} \sum_{j=1}^{k} R_\xi (t_l , t_j )z_l z_j \right)\]
где $z_j$ - произвольные вещественные числа, а $t_j \in T$ и
\[m_\xi (t_j) = M\{\xi (t_j)\}, \qquad  R_\xi (t_l, t_j) = \textbf{cov} \{\xi(t_l), \xi(t_j)\}\]

Если обозначить через $(a, b) = \sum_{l=1}^{k} a_j b_j$ скалярное произведение векторов $a, b \in \mathbb{R}^{k}$, то характеристическую функцию можно представить в виде
\[\Psi_\xi (z; t_1, \dots, t_k) = exp\left( i(z, m_\xi) - \frac{1}{2} (R(_\xi z, z) \right),\]

где $z=\{z_1, \dots, z_k\}^{*} , m_\xi = \{ m_\xi (t_1), \dots, m_\xi(t_k)\}^{*}, R_\xi = \{R_\xi (t_i, t_j) \}_{i,j=1,\dots,k}$

$\newline$
То есть характеристичекая функция полностью определяет распределение совокупности случайных величин. \cite{ShiryaevVeroyatnost1}

\subsection*{Свойства гауссовских векторов}

 \begin{enumerate}
   \item Каждая компонента нормального вектора $\xi \in N(\mu, R)$ имеет нормальное распределение, причем $\xi_j \in N(\mu_j , R_{jj})$. Обратное неверно! То есть если у некоторого случайного вектора все компоненты по отдельности имеют нормальное распределение, то это значит, что вектор целиком имеет нормальное распределение. \cite{NugmanovBRP2014}
   $\newline$
   \textit{Дело в том, что совместное распределение компонент вектора в общем случае не определяется их частными распределениями. Однако если у слуайного вектора компоненты независимы в совокупности и имеют нормальное распределение, то тогда и вектор имеет нормальное распределение.}
   \item Гауссовский случайный вектор $\eta = \{\eta_1, \dots, \eta_k\}^{*}$ с математическим ожиданием $m_\eta$ и ковариационной матрицей $R_\eta$ имеет плотность распределения $p_\eta (x)$ тогда и только тогда, когда матрица $R_\eta$ - невырожденная, то есть $det[R_\eta] > 0$. В этом случае плотность распределения имеет следующий вид
    \[p_\eta (x) = (2\pi)^{-k/2} (det[R_\eta])^{-1/2} exp \left( - \frac{1}{2} (x - m_\eta)(R_\eta)^{-1} (x - m_\eta) \right) \]

    Таким образом если матрица $R_\xi = \{R_\xi (t_i, t_j )\}_{i,j=1,\dots,k}$ положительно определена, то совместное распределение сечений $\{ \xi(t_1), \dots, \xi(t_k)\}$ имеет плотность вероятности
    \[p_\xi (x; t_1, \dots, t_k) = (2\pi)^{-k/2} (det[R_\xi])^{-1/2} exp \left( - \frac{1}{2} (x - m_\xi)(R_\xi)^{-1} (x - m_\xi) \right) \]

    Если же матрица $R$ вырождена, то плотности распределения у вектора нет. В этом случае найдется вектор $c \ne 0$ такой, что $Rc = 0$б то есть $R$ имеет линейно зависимые столбцы и строки. Из этого следует, что компоненты вектора линейно связнаны, то есть вероятностная мера сконцентрирована на подпространстве меньшей размерности, а не на всем пространстве $\mathbb{R}^{n}$. \cite{ShiryaevVeroyatnost1}

    \item Пусть $\xi \in N(\mu, R), \xi \in \mathbb{R}^{n}$. Тогда для любой матрицы $A \in \mathbb{R}^{k\times n}$ (необязательно невырожденной и даже необязательно квадратной) вектор $A\xi$ тоже будет нормальным, причем  $A\xi \in N(A\mu, ARA^T)$. \cite{NugmanovBRP2014}

    \item Вектор $\xi$ является нормальным тогда и только тогда, когда любая линейная комбинация его компонент дает нормальную случайную величину или константу, и все его компоненты некоррелированы. \cite{ShiryaevVeroyatnost1}

    \item Компоненты нормального случайного вектора некоррелированы тогда и только тогда, когда независимы. \cite{NugmanovBRP2014}
    $\newline$
    \textit{Здесь нужно обратить внимание на то, что речь идет именно о компонентах нормального вектора, а не просто о нормальных случайных величинах. Просто нормальные случайные величины могут быть и некоррелированными, и зависимыми. Но если случайные величины не только нормальные, но и являются компонентами нормального вектора (более сильное свойство), то тогда из их некоррелированности следует их независимость.}

    \item Семейство конечномерных гауссовских распределений, соответствующее семейству характеристических функций $\Psi_\xi$, удовлетворяет условиям 1-6 теоремы Колмогорова.Таким образом, произвольный набор $\{\xi(t_1), \dots,\xi(t_k)\}$ сечений гауссовского случайного процесса является случайным вектором с гауссовским распределением. Также подчеркнем, что все эти распределения \textbf{согласованы} (см. лекцию о т. Колмогорова) \cite{ShiryaevVeroyatnost1}

    \item Из определения гауссовского процесса следует, что семейство его конечномерныз распределений полностью определяется двумя моментными характеристиками: математическим ожиданием и ковариационной функцией. \cite{ShiryaevVeroyatnost1}

 \end{enumerate}

\subsection*{Винеровский процесс}


\begin{definition} Гауссовский случайный процесс $\{\xi(t), t \geq 0 \}$ с непрерывным временем и моментными характеристиками 
\[M\{\xi(t)\} = 0 \quad \textbf{cov}\{\xi(t), \xi(s)\} = min(t, s) \quad t, s \geq 0\]
и выходящий из нуля, то есть $\xi(0) = 0$, называется \textbf{стандартным винеровским процессом} (или процессом броуновского движения). Это важнейший пример нормального случайного процесса. \cite{ShiryaevVeroyatnost1}
\end{definition}
$\newline$
$\newline$
Рассмотрим свойства винеровского процесса, которые можно вывести непосредственно из определения.
$\newline$
\begin{enumerate}
    \item Приращения процесса броуновского движения на непересекающихся промежутках времени независимы. \cite{ShiryaevVeroyatnost1}

    
    \textit{Покажем это и найдем распределение произвольного приращения.}
    $\newline$
    Прежде всего заметим, что совокупность приращений процесса броуновского движения $\xi(t_1) - \xi(t_0), \xi(t_2) - \xi(t_1), \dots, \xi(t_k) - \xi(t_{k-1})$, где $0 = t_0 < t_1 < \dots < t_k$ и $\xi(t_0) = 0$, имеет гауссовское распределение в силу гауссовости случайного вектора $\{\xi(t_1), \xi(t_2), \dots, \xi(t_k)\}^{*}$, поэтому для доказательства независимости приращений достаточно установить их некоррелированность. Итак, для мометнов времени $t_i < t_j$ верно
    \[\textbf{cov}\{\xi(t_i) - \xi(t_{i-1}), \xi(t_j) - \xi(t_{j-1})\} = \newline\]
    \[= min(t_i, t_j) - min(t_i, t_{j-1}) - min(t_{i-1}, t_j) + min (t_{i-1}, t_{j-1}) = 0\]

    что означает некоррельрованность приращений процесса $\xi(t)$ на промежутках $[t_{i-1}, t_i]$ и $[t_{j-1}, t_j]$.
    $\newline$
    Как уже отмечалось, приращение $\xi(t) - \xi(s)$ имеет гауссовское распределение, поэтому
    \[\xi(t) - \xi(s) \sim N(0; |t-s|)\]
    так как $M\{\xi(t) - \xi(s)\} = 0$ и $D\{\xi(t) - \xi(s) \} = t + s - 2min(t, s) = |t - s|$

    \item Найдем плотность конечномерного распределения процесса броуновского движения. \cite{ShiryaevVeroyatnost1}
    \[\eta_1 = \xi(t_1) - \xi(t_0), \eta_2 = \xi(t_2) - \xi(t_1), \dots, \eta_k = \xi(t_k) - \xi(t_{k-1})\]
    где $0 = t_0 < t_1 < \dots < t_k $
    $\newline$
    Поскольку $\xi(t_0) = 0$, то
    \[\xi(t_1) = \eta_1, \xi(t_2) = \eta_1 + \eta_2,  \dots, \xi(t_k) = \eta_1 + \dots + \eta_k\]

    Пусть $p_\eta$ - плотность распределения вектора $\eta = \{\eta_1, \dots, \eta_k\}^{*}$, а $p_{\eta_i}$ - плотность распределения приращения $\eta_i$. Тогда плотность распределения вектора $\xi = \{\xi(t_1), \dots, \xi(t_k)\}^{*}$ равна
    \[p_\xi (x_1, \dots, x_k; t_1, \dots, t_k) = p_\eta (x_1, x_2 - x_1, \dots, x_k - x_{k-1}) = \newline\]
    \[p_{\eta_1} (x_1) p_{\eta_2}(x_2 - x_1)\dots p_{\eta_k}(k_k - x_{k-1})\]

    где первое равенство следует из того, что якобиан преобразования $\eta \to \xi$ по модулю 1, а второе получено с учетом независимости случайных величин $\eta_i$. Тогда из свойств 1 следует
    \[p_\xi (x_1, \dots, x_k; t_1, \dots, t_k) = \prod_{i=1}^{k} \frac{1}{\sqrt{2\pi |t_i - t_{i-1}|}} exp \left\{ -\frac{(x_i - x_{i-1})^2}{2|t_i - t_{i-1}|} \right\}\]
    где $t_0 = 0, x_0 = 0$


    В приложениях весьма часто приходится иметь дело с \textbf{n-мерными гауссовскими процесами}, где $n>1$. По аналогии с введенным ранее определением гауссовского процесса мы можем назвать процесс  $\xi(t) \in \mathbb{R}^{n} , t \in T$ гауссовским, если при любых $t_1, \dots, t_k \in T, k \geq 1,  (n \times k)$ - мерный случайный вектор $\eta = \{ \xi^* (t_1), \dots, \xi^* (t_k)\}^{*}$ имеет гауссовское $(n \times k)$ - мерное распределение. Все свойства такого процесса полностью определяются n-мерной функцией математического ожидания $m_\xi (t)$ и $(n \times n)$ - мерной (то есь матричной) ковариационной функцией $R_\xi (t, s)$, которая вычисляется следующим образом \cite{ShiryaevVeroyatnost1}:
    \[R_\xi (t, s) = M\left\{ (\xi(t) - m_\xi(t))(\xi(s) - m_\xi(s))^* \right\} = M\left\{\xi(t)\xi^* (s)\right\} - m_\xi (t)m^* _\xi (s)\]

\end{enumerate}

